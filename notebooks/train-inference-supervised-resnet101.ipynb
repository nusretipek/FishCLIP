{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "893c09e7-2442-4ac8-b527-0be508ba75da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ResNet-101 supervised training script.\n",
    "\"\"\"\n",
    "\n",
    "# import libraries\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "from tabulate import tabulate\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "\n",
    "# import taxa from parent directory\n",
    "sys.path.insert(0, str(Path.cwd().resolve().parent))\n",
    "from fishTaxa import taxaTuples\n",
    "\n",
    "# paths (anchor to repo root one level up)\n",
    "NOTEBOOK_DIR: Path = Path.cwd().resolve()\n",
    "ROOT_DIR: Path = NOTEBOOK_DIR.parent\n",
    "\n",
    "# constants\n",
    "BATCH_SIZE: int = 16\n",
    "EPOCHS: int = 15\n",
    "LEARNING_RATE: float = 1e-5\n",
    "WEIGHT_DECAY: float = 0.01\n",
    "LABEL_SMOOTHING: float = 0.1\n",
    "STEP_LOG_INTERVAL: int = 10\n",
    "EVAL_FOLDER: str = str(ROOT_DIR / \"zeroCLIP\")\n",
    "DATASET_ROOT: str = str(ROOT_DIR / \"dataCLIP\")\n",
    "SEED: int = 0\n",
    "ENABLE_REPRODUCIBILITY = True\n",
    "\n",
    "# reproducibility settings\n",
    "if ENABLE_REPRODUCIBILITY:\n",
    "    torch.manual_seed(SEED)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(SEED)\n",
    "        torch.cuda.manual_seed_all(SEED)\n",
    "    os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":16:8\"\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    try:\n",
    "        torch.use_deterministic_algorithms(True)\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa66899a-4a11-44ba-bdc1-7a9021e06748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select device\n",
    "device: str = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# build families and label mappings from taxa\n",
    "families: List[str] = sorted(list({species[4] for species in taxaTuples}))\n",
    "familyToIdx = {family: idx for idx, family in enumerate(families)}\n",
    "idxToFamily = {idx: family for family, idx in familyToIdx.items()}\n",
    "numClasses: int = len(families)\n",
    "\n",
    "print(f\"Number of unique families: {numClasses}\")\n",
    "print(f\"Families: {families}\\n\")\n",
    "\n",
    "\n",
    "# define transforms\n",
    "trainTransform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "evalTransform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "def buildDatasetLists(root: str = DATASET_ROOT) -> Tuple[List[str], List[int]]:\n",
    "    \"\"\"\n",
    "    Build parallel lists for image paths and numeric labels using taxa from fishTaxa.\n",
    "\n",
    "    Args:\n",
    "        root: Dataset root containing subfolders named by binomial (Genus_species).\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (imagePaths, labels) aligned by index.\n",
    "    \"\"\"\n",
    "    rootPath = Path(root)\n",
    "    imagePaths: List[str] = []\n",
    "    labels: List[int] = []\n",
    "\n",
    "    for species in taxaTuples:\n",
    "        binom, _common, _cls, _order, family, _genus = species\n",
    "        familyIdx = familyToIdx[family]\n",
    "        folderPath = rootPath / binom.replace(\" \", \"_\")\n",
    "        if not folderPath.exists():\n",
    "            continue\n",
    "        for img in sorted(folderPath.glob(\"*\")):\n",
    "            if img.suffix.lower() in {\".jpg\", \".jpeg\", \".png\", \".webp\"}:\n",
    "                imagePaths.append(str(img))\n",
    "                labels.append(familyIdx)\n",
    "\n",
    "    assert len(imagePaths) == len(labels)\n",
    "    return imagePaths, labels\n",
    "\n",
    "\n",
    "class FishDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset yielding (imageTensor, familyLabel) pairs for supervised training.\n",
    "\n",
    "    Attributes:\n",
    "        imagePaths: List of image file paths.\n",
    "        labels: List of integer family labels.\n",
    "        transform: Optional torchvision transform to apply to images.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, imagePaths: List[str], labels: List[int], transform=None):\n",
    "        self.imagePaths: List[str] = imagePaths\n",
    "        self.labels: List[int] = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.imagePaths)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        imgPath = self.imagePaths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        img = Image.open(imgPath)\n",
    "        img = ImageOps.exif_transpose(img)\n",
    "        if img.mode == \"P\" and (\"transparency\" in img.info or img.info.get(\"transparency\") is not None):\n",
    "            img = img.convert(\"RGBA\").convert(\"RGB\")\n",
    "        else:\n",
    "            img = img.convert(\"RGB\")\n",
    "        img.load()\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "\n",
    "# build dataset and dataloader\n",
    "imageData, labelData = buildDatasetLists(DATASET_ROOT)\n",
    "dataset = FishDataset(imageData, labelData, transform=trainTransform)\n",
    "trainDataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc84aa6c-0100-4556-a48c-51235fbd37e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model setup\n",
    "model = models.resnet101(weights=\"IMAGENET1K_V1\")\n",
    "numFeatures = model.fc.in_features\n",
    "model.fc = nn.Sequential(  \n",
    "    nn.Linear(numFeatures, 1024),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(1024, numClasses),\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def predictImage(imagePath: str, model: torch.nn.Module, transform, device: str, topk: int = 5,) -> List[Tuple[float, str]]:\n",
    "    \"\"\"\n",
    "    Predict top-k families for a single image using the current model.\n",
    "\n",
    "    Args:\n",
    "        imagePath: Path to the image file.\n",
    "        model: The classification model.\n",
    "        transform: The evaluation transform to apply.\n",
    "        device: Device string (e.g., 'cuda:0' or 'cpu').\n",
    "        topk: Number of top predictions to return.\n",
    "\n",
    "    Returns:\n",
    "        List of (score, familyLabel) pairs sorted by score desc.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    img = Image.open(imagePath)\n",
    "    img = ImageOps.exif_transpose(img)\n",
    "    if img.mode == \"P\" and (\"transparency\" in img.info or img.info.get(\"transparency\") is not None):\n",
    "        img = img.convert(\"RGBA\").convert(\"RGB\")\n",
    "    else:\n",
    "        img = img.convert(\"RGB\")\n",
    "    img.load()\n",
    "\n",
    "    image = transform(img).unsqueeze(0).to(device)\n",
    "    outputs = model(image)\n",
    "    probs = torch.softmax(outputs, dim=1).squeeze(0)\n",
    "    k = min(topk, numClasses)\n",
    "    scores, indices = torch.topk(probs, k=k, largest=True, sorted=True)\n",
    "    return [(float(scores[i]), idxToFamily[int(indices[i])]) for i in range(k)]\n",
    "\n",
    "\n",
    "def runEvaluation(imgFolder: str) -> None:\n",
    "    \"\"\"\n",
    "    Evaluate images in a folder; expects filenames like Genus_species_Family.* for true family.\n",
    "\n",
    "    Args:\n",
    "        imgFolder: Folder containing images to evaluate.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(imgFolder):\n",
    "        print(f\"{imgFolder} does not exist.\")\n",
    "        return\n",
    "\n",
    "    imgFiles = sorted(glob.glob(f\"{imgFolder}/*\"))\n",
    "    if not len(imgFiles):\n",
    "        print(f\"{imgFolder} is empty.\")\n",
    "        return\n",
    "\n",
    "    rows = []\n",
    "    evalResults = []\n",
    "    for name in imgFiles:\n",
    "        results = predictImage(name, model, evalTransform, device, topk=3)\n",
    "        nameSplit = os.path.basename(name).split(\".\")[0].split(\"_\")\n",
    "        if len(nameSplit) >= 3:\n",
    "            trueFamily = nameSplit[2]\n",
    "        else:\n",
    "            trueFamily = \"Unknown\"\n",
    "\n",
    "        predFamilies = [label for _, label in results]\n",
    "        row = [f\"{nameSplit[0]} {nameSplit[1] if len(nameSplit) > 1 else ''}\"] + [trueFamily]\n",
    "        row += [f\"{label} ({score:.3f})\" for score, label in results]\n",
    "        rows.append(row)\n",
    "\n",
    "        if trueFamily in familyToIdx:\n",
    "            isTop1 = predFamilies[0] == trueFamily\n",
    "            isTop3 = trueFamily in predFamilies\n",
    "            evalResults.append(\n",
    "                {\n",
    "                    \"name\": os.path.basename(name),\n",
    "                    \"true_family\": trueFamily,\n",
    "                    \"pred_top1\": predFamilies[0],\n",
    "                    \"pred_top3\": predFamilies,\n",
    "                    \"top1_correct\": isTop1,\n",
    "                    \"top3_correct\": isTop3,\n",
    "                },\n",
    "            )\n",
    "\n",
    "    headers = [\"Image\", \"True Family\", \"Top-1\", \"Top-2\", \"Top-3\"]\n",
    "    print(tabulate(rows, headers=headers, tablefmt=\"fancy_grid\"), \"\\n\")\n",
    "\n",
    "    if len(evalResults) > 0:\n",
    "        correctTop1 = sum(r[\"top1_correct\"] for r in evalResults)\n",
    "        correctTop3 = sum(r[\"top3_correct\"] for r in evalResults)\n",
    "        total = len(evalResults)\n",
    "    else:\n",
    "        print(\"\\nNo valid images found with families in the training set.\\n\")\n",
    "\n",
    "\n",
    "# initial evaluation (before fine-tuning)\n",
    "print(\"=\" * 50)\n",
    "print(\"INITIAL EVALUATION (Before fine-tuning)\")\n",
    "print(\"=\" * 50)\n",
    "runEvaluation(EVAL_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529c9f2f-9e2a-4a33-954a-d6d64f26dc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training configuration\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=LABEL_SMOOTHING)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "# training loop\n",
    "print(\"=\" * 50)\n",
    "print(\"FINE-TUNING SUPERVISED RESNET-101 MODEL\")\n",
    "print(\"=\" * 50)\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    epochLossSum = 0.0\n",
    "    epochCorrect = 0\n",
    "    epochTotal = 0\n",
    "    stepIdx = 0\n",
    "\n",
    "    print(15 * \"-\", f\"Epoch {epoch+1}\", 15 * \"-\")\n",
    "    for batch in trainDataloader:\n",
    "        optimizer.zero_grad()\n",
    "        images, labels = batch\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        batchCorrect = (predicted == labels).sum().item()\n",
    "        batchTotal = labels.size(0)\n",
    "\n",
    "        epochLossSum += loss.item() * batchTotal\n",
    "        epochCorrect += batchCorrect\n",
    "        epochTotal += batchTotal\n",
    "\n",
    "        stepIdx += 1\n",
    "        if stepIdx % STEP_LOG_INTERVAL == 0:\n",
    "            runningLoss = epochLossSum / epochTotal\n",
    "            runningAcc = 100 * epochCorrect / epochTotal\n",
    "            print(f\"Step {stepIdx}/{len(trainDataloader)} | Loss: {runningLoss:.4f} | Acc: {runningAcc:.2f}%\",)\n",
    "\n",
    "    scheduler.step()\n",
    "    epochAvgLoss = epochLossSum / epochTotal\n",
    "    epochAcc = 100 * epochCorrect / epochTotal\n",
    "    print(f\"\\nEpoch {epoch + 1} Summary:\")\n",
    "    print(f\"  Average Loss: {epochAvgLoss:.4f}\")\n",
    "    print(f\"  Training Accuracy: {epochAcc:.2f}%\\n\")\n",
    "\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"EVALUATION AFTER EPOCH {epoch + 1}\")\n",
    "    print(\"-\" * 30)\n",
    "    runEvaluation(EVAL_FOLDER)\n",
    "\n",
    "# save checkpoint\n",
    "torch.save(model.state_dict(), f'resnet101_supervised_{EPOCHS}.pt')\n",
    "print(f\"Training complete and model saved to: ./resnet101_supervised_{EPOCHS}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce740452-ee51-43a5-9bfc-f26279c5f701",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH: str = \"resnet101_supervised_15.pt\"\n",
    "IMAGE_PATH: str = str(ROOT_DIR / \"zeroCLIP\" / \"Sphyraena_novaehollandiae_Sphyraenidae.jpg\")\n",
    "TOP_K: int = 3\n",
    "\n",
    "\n",
    "def buildFamilies() -> Tuple[List[str], dict, dict]:\n",
    "    \"\"\"\n",
    "    Build family label lists and mappings from fishTaxa.taxaTuples.\n",
    "\n",
    "    Returns:\n",
    "        families: Sorted unique family names.\n",
    "        familyToIdx: Mapping family -> index.\n",
    "        idxToFamily: Mapping index -> family.\n",
    "    \"\"\"\n",
    "    families: List[str] = sorted(list({species[4] for species in taxaTuples}))\n",
    "    familyToIdx = {family: idx for idx, family in enumerate(families)}\n",
    "    idxToFamily = {idx: family for family, idx in familyToIdx.items()}\n",
    "    return families, familyToIdx, idxToFamily\n",
    "\n",
    "\n",
    "def makeEvalTransform():\n",
    "    \"\"\"\n",
    "    Create the evaluation transform matching the training settings.\n",
    "    \"\"\"\n",
    "    return transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "\n",
    "def buildModel(numClasses: int, device: str) -> torch.nn.Module:\n",
    "    \"\"\"\n",
    "    Build the ResNet101 model with the same classifier head as training.\n",
    "    \"\"\"\n",
    "    model = models.resnet101(weights=\"IMAGENET1K_V1\")\n",
    "    numFeatures = model.fc.in_features \n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Linear(numFeatures, 1024),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(1024, numClasses),\n",
    "    )\n",
    "    return model.to(device)\n",
    "\n",
    "\n",
    "def loadWeights(model: torch.nn.Module, modelPath: str, device: str) -> None:\n",
    "    \"\"\"\n",
    "    Load weights into the model. Accepts raw state_dict or dict with 'state_dict'.\n",
    "    \"\"\"       \n",
    "    print(f\"Loading checkpoint from: {modelPath}\")\n",
    "    ckpt = torch.load(modelPath, weights_only=False, map_location=device)\n",
    "    state = ckpt.get(\"state_dict\", ckpt) if isinstance(ckpt, dict) else ckpt\n",
    "    try:\n",
    "        model.load_state_dict(state, strict=False)\n",
    "        print(\"Model weights loaded successfully.\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: could not load some weights â†’ {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def predictImage(\n",
    "    imagePath: str,\n",
    "    model: torch.nn.Module,\n",
    "    transform,\n",
    "    device: str,\n",
    "    idxToFamily: dict,\n",
    "    topk: int = 3,\n",
    ") -> List[Tuple[float, str]]:\n",
    "    \"\"\"\n",
    "    Predict top-k families for a single image using the supervised classifier.\n",
    "\n",
    "    Args:\n",
    "        imagePath: Path to the image file.\n",
    "        model: ResNet101 classifier.\n",
    "        transform: Evaluation transform.\n",
    "        device: Torch device string.\n",
    "        idxToFamily: Mapping index -> family name.\n",
    "        topk: Number of top predictions to return.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    img = Image.open(imagePath)\n",
    "    img = ImageOps.exif_transpose(img)\n",
    "    if img.mode == \"P\" and (\"transparency\" in img.info or img.info.get(\"transparency\") is not None):\n",
    "        img = img.convert(\"RGBA\").convert(\"RGB\")\n",
    "    else:\n",
    "        img = img.convert(\"RGB\")\n",
    "    img.load()\n",
    "\n",
    "    image = transform(img).unsqueeze(0).to(device)\n",
    "    outputs = model(image)\n",
    "    probs = torch.softmax(outputs, dim=1).squeeze(0)\n",
    "    k = min(topk, probs.shape[-1])\n",
    "    scores, indices = torch.topk(probs, k=k, largest=True, sorted=True)\n",
    "    return [(float(scores[i]), idxToFamily[int(indices[i])]) for i in range(k)]\n",
    "\n",
    "# inference\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "families, _familyToIdx, idxToFamily = buildFamilies()\n",
    "model = buildModel(numClasses=len(families), device=device)\n",
    "loadWeights(model, MODEL_PATH, device)\n",
    "\n",
    "transform = makeEvalTransform()\n",
    "results = predictImage(IMAGE_PATH, model, transform, device, idxToFamily, topk=TOP_K)\n",
    "\n",
    "print(f\"Image: {Path(IMAGE_PATH).name}\")\n",
    "for rank, (score, label) in enumerate(results, start=1):\n",
    "    print(f\"Top-{rank}: {label} ({score:.4f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
